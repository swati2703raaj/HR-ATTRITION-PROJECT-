{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VFKmuqx66UFH2pTtr3vLiRMWLauRxjDb",
      "authorship_tag": "ABX9TyPvbtiCipd3uUEl+oour85Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swati2703raaj/HR-ATTRITION-PROJECT-/blob/main/HR_ATTRITION_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: IMPORTING REQUIRED LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ],
      "metadata": {
        "id": "KZz5L-giilFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: LOAD THE DATA\n",
        "df = pd.read_csv(\"/content/IBM-HR-Analytics-Employee-Attrition-and-Performance-Revised.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "AcluQrFHmGgZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "166e545e-6896-4cc6-ccc2-cc1e32f4866c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
              "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
              "1   49        No  Travel_Frequently        279  Research & Development   \n",
              "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
              "3   33        No  Travel_Frequently       1392  Research & Development   \n",
              "4   27        No      Travel_Rarely        591  Research & Development   \n",
              "\n",
              "   DistanceFromHome      Education EducationField EnvironmentSatisfaction  \\\n",
              "0                 1        College  Life Sciences                  Medium   \n",
              "1                 8  Below College  Life Sciences                    High   \n",
              "2                 2        College          Other               Very High   \n",
              "3                 3         Master  Life Sciences               Very High   \n",
              "4                 2  Below College        Medical                     Low   \n",
              "\n",
              "   Gender  ...  PerformanceRating RelationshipSatisfaction StockOptionLevel  \\\n",
              "0  Female  ...          Excellent                      Low                0   \n",
              "1    Male  ...        Outstanding                Very High                1   \n",
              "2    Male  ...          Excellent                   Medium                0   \n",
              "3  Female  ...          Excellent                     High                0   \n",
              "4    Male  ...          Excellent                Very High                1   \n",
              "\n",
              "  TotalWorkingYears TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
              "0                 8                     0             Bad               6   \n",
              "1                10                     3          Better              10   \n",
              "2                 7                     3          Better               0   \n",
              "3                 8                     3          Better               8   \n",
              "4                 6                     3          Better               2   \n",
              "\n",
              "   YearsInCurrentRole  YearsSinceLastPromotion YearsWithCurrManager  \n",
              "0                   4                        0                    5  \n",
              "1                   7                        1                    7  \n",
              "2                   0                        0                    0  \n",
              "3                   7                        3                    0  \n",
              "4                   2                        2                    2  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff448d45-e4a0-48f7-8d19-227da8819f42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>...</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1102</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1</td>\n",
              "      <td>College</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>Medium</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Low</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>Bad</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>279</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8</td>\n",
              "      <td>Below College</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>High</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>Outstanding</td>\n",
              "      <td>Very High</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>Better</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1373</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>College</td>\n",
              "      <td>Other</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Medium</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>Better</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>1392</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>3</td>\n",
              "      <td>Master</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>Very High</td>\n",
              "      <td>Female</td>\n",
              "      <td>...</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>High</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>Better</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>591</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>Below College</td>\n",
              "      <td>Medical</td>\n",
              "      <td>Low</td>\n",
              "      <td>Male</td>\n",
              "      <td>...</td>\n",
              "      <td>Excellent</td>\n",
              "      <td>Very High</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>Better</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff448d45-e4a0-48f7-8d19-227da8819f42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff448d45-e4a0-48f7-8d19-227da8819f42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff448d45-e4a0-48f7-8d19-227da8819f42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df85c1b2-94ed-497a-8332-80477441fd9e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df85c1b2-94ed-497a-8332-80477441fd9e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df85c1b2-94ed-497a-8332-80477441fd9e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IUNpMro2leLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e9ecbc5-adfa-4293-8c46-91faaf1e7477"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: DROP NON-USEFUL COLUMNS\n",
        "# The previously specified columns (EmployeeNumber, EmployeeCount, Over18, StandardHours) were not found in the dataframe."
      ],
      "metadata": {
        "id": "8fOmK2lXipah"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: ENCODE TARGET VARIABLE (Binary conversion)\n",
        "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n"
      ],
      "metadata": {
        "id": "FdjUhe88i2E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: FEATURE ENGINEERING\n",
        "df['Tenure_Ratio'] = df['YearsAtCompany'] / df['TotalWorkingYears'].replace(0,np.nan)\n",
        "df['Income_Band'] = pd.qcut(df['MonthlyIncome'], 5, labels=False)\n",
        "df['Promotion_Gap'] = df['YearsAtCompany'] - df['YearsSinceLastPromotion']\n"
      ],
      "metadata": {
        "id": "5zLuxd_mi66_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: SEPARATE FEATURES & TARGET\n",
        "X = df.drop(\"Attrition\", axis=1)\n",
        "y = df['Attrition']\n"
      ],
      "metadata": {
        "id": "gmZwn09yi-Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: ONE-HOT ENCODE CATEGORICAL VARIABLES\n",
        "X = pd.get_dummies(X, drop_first=True)\n"
      ],
      "metadata": {
        "id": "3872OV6fjCGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: TRAIN-TEST SPLIT (WITH STRATIFICATION)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "eGMArhM6jEYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: FEATURE SCALING (Required for Logistic Regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "XBTp3Uv5jFio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 10: TRAIN BOTH MODELS\n",
        "log_model = LogisticRegression(max_iter=2000)\n",
        "log_model.fit(X_train, y_train)\n",
        "\n",
        "tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "0Qw4jQo_jL-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 11: MODEL PREDICTIONS\n",
        "log_pred = log_model.predict(X_test)\n",
        "tree_pred = tree_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "VaseJ9RNjUQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 12: MODEL EVALUATION\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "print(classification_report(y_test, log_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, log_pred))\n",
        "\n",
        "print(\"\\nDecision Tree Results:\")\n",
        "print(classification_report(y_test, tree_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, tree_pred))\n"
      ],
      "metadata": {
        "id": "Ez05OATcjcQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9045202d"
      },
      "source": [
        "# Task\n",
        "Perform a code review on the provided notebook code, focusing on data loading and initial preparation, feature engineering (Tenure_Ratio, Income_Band, Promotion_Gap), data preprocessing (one-hot encoding, train-test split, feature scaling), and model training and evaluation for both Logistic Regression and Decision Tree models. Provide a comprehensive summary of any corrections made or suggested improvements to the machine learning pipeline. The data used is from `/content/IBM-HR-Analytics-Employee-Attrition-and-Performance-Revised.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef11c0b8"
      },
      "source": [
        "## Review Data Loading and Initial Preparation\n",
        "\n",
        "### Subtask:\n",
        "Examine the data loading, target variable encoding, and any column dropping steps for correctness and efficiency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e15454be"
      },
      "source": [
        "**Reasoning**:\n",
        "To review the data loading, target variable encoding, and column dropping steps, I will first display the DataFrame's head and information to confirm correct loading. Then, I will inspect the columns identified for dropping and check for other potentially non-useful columns by examining their unique values. Finally, I will verify the 'Attrition' column's current state to confirm the encoding step's impact.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a56525ad",
        "outputId": "63770fe4-043d-4631-814f-df5dae819854"
      },
      "source": [
        "print(\"--- Reviewing Data Loading ---\")\n",
        "print(\"DataFrame Head (from initial load):\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n--- Reviewing Column Dropping (Cell 8fOmK2lXipah) ---\")\n",
        "columns_to_check = ['EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours']\n",
        "found_columns = [col for col in columns_to_check if col in df.columns]\n",
        "\n",
        "if found_columns:\n",
        "    print(f\"The following specified columns were found: {found_columns}\")\n",
        "    for col in found_columns:\n",
        "        print(f\"  '{col}' unique values: {df[col].unique()}\")\n",
        "        print(f\"  '{col}' value counts:\\n{df[col].value_counts()}\")\n",
        "else:\n",
        "    print(\"The previously specified columns (EmployeeNumber, EmployeeCount, Over18, StandardHours) are NOT found in the dataframe as indicated in the notebook.\")\n",
        "\n",
        "print(\"\\nChecking for other potential non-useful columns (e.g., constant or unique identifiers):\")\n",
        "for col in df.columns:\n",
        "    if df[col].nunique() == 1:\n",
        "        print(f\"  Column '{col}' is constant with value: {df[col].iloc[0]}\")\n",
        "    elif df[col].nunique() == len(df):\n",
        "        print(f\"  Column '{col}' has all unique values (potential identifier).\")\n",
        "\n",
        "print(\"\\n--- Reviewing Target Variable Encoding (Cell FdjUhe88i2E5) ---\")\n",
        "print(\"Current unique values in 'Attrition' column before encoding execution:\")\n",
        "print(df['Attrition'].value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Reviewing Data Loading ---\n",
            "DataFrame Head (from initial load):\n",
            "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
            "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
            "1   49        No  Travel_Frequently        279  Research & Development   \n",
            "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
            "3   33        No  Travel_Frequently       1392  Research & Development   \n",
            "4   27        No      Travel_Rarely        591  Research & Development   \n",
            "\n",
            "   DistanceFromHome      Education EducationField EnvironmentSatisfaction  \\\n",
            "0                 1        College  Life Sciences                  Medium   \n",
            "1                 8  Below College  Life Sciences                    High   \n",
            "2                 2        College          Other               Very High   \n",
            "3                 3         Master  Life Sciences               Very High   \n",
            "4                 2  Below College        Medical                     Low   \n",
            "\n",
            "   Gender  ...  PerformanceRating RelationshipSatisfaction StockOptionLevel  \\\n",
            "0  Female  ...          Excellent                      Low                0   \n",
            "1    Male  ...        Outstanding                Very High                1   \n",
            "2    Male  ...          Excellent                   Medium                0   \n",
            "3  Female  ...          Excellent                     High                0   \n",
            "4    Male  ...          Excellent                Very High                1   \n",
            "\n",
            "  TotalWorkingYears TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
            "0                 8                     0             Bad               6   \n",
            "1                10                     3          Better              10   \n",
            "2                 7                     3          Better               0   \n",
            "3                 8                     3          Better               8   \n",
            "4                 6                     3          Better               2   \n",
            "\n",
            "   YearsInCurrentRole  YearsSinceLastPromotion YearsWithCurrManager  \n",
            "0                   4                        0                    5  \n",
            "1                   7                        1                    7  \n",
            "2                   0                        0                    0  \n",
            "3                   7                        3                    0  \n",
            "4                   2                        2                    2  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 31 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Age                       1470 non-null   int64 \n",
            " 1   Attrition                 1470 non-null   object\n",
            " 2   BusinessTravel            1470 non-null   object\n",
            " 3   DailyRate                 1470 non-null   int64 \n",
            " 4   Department                1470 non-null   object\n",
            " 5   DistanceFromHome          1470 non-null   int64 \n",
            " 6   Education                 1470 non-null   object\n",
            " 7   EducationField            1470 non-null   object\n",
            " 8   EnvironmentSatisfaction   1470 non-null   object\n",
            " 9   Gender                    1470 non-null   object\n",
            " 10  HourlyRate                1470 non-null   int64 \n",
            " 11  JobInvolvement            1470 non-null   object\n",
            " 12  JobLevel                  1470 non-null   object\n",
            " 13  JobRole                   1470 non-null   object\n",
            " 14  JobSatisfaction           1470 non-null   object\n",
            " 15  MaritalStatus             1470 non-null   object\n",
            " 16  MonthlyIncome             1470 non-null   int64 \n",
            " 17  MonthlyRate               1470 non-null   int64 \n",
            " 18  NumCompaniesWorked        1470 non-null   int64 \n",
            " 19  OverTime                  1470 non-null   object\n",
            " 20  PercentSalaryHike         1470 non-null   int64 \n",
            " 21  PerformanceRating         1470 non-null   object\n",
            " 22  RelationshipSatisfaction  1470 non-null   object\n",
            " 23  StockOptionLevel          1470 non-null   int64 \n",
            " 24  TotalWorkingYears         1470 non-null   int64 \n",
            " 25  TrainingTimesLastYear     1470 non-null   int64 \n",
            " 26  WorkLifeBalance           1470 non-null   object\n",
            " 27  YearsAtCompany            1470 non-null   int64 \n",
            " 28  YearsInCurrentRole        1470 non-null   int64 \n",
            " 29  YearsSinceLastPromotion   1470 non-null   int64 \n",
            " 30  YearsWithCurrManager      1470 non-null   int64 \n",
            "dtypes: int64(15), object(16)\n",
            "memory usage: 356.1+ KB\n",
            "\n",
            "--- Reviewing Column Dropping (Cell 8fOmK2lXipah) ---\n",
            "The previously specified columns (EmployeeNumber, EmployeeCount, Over18, StandardHours) are NOT found in the dataframe as indicated in the notebook.\n",
            "\n",
            "Checking for other potential non-useful columns (e.g., constant or unique identifiers):\n",
            "\n",
            "--- Reviewing Target Variable Encoding (Cell FdjUhe88i2E5) ---\n",
            "Current unique values in 'Attrition' column before encoding execution:\n",
            "Attrition\n",
            "No     1233\n",
            "Yes     237\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ee9ee4c"
      },
      "source": [
        "**Reasoning**:\n",
        "Based on the review of the previous output, the data loading was successful. The specified columns for dropping ('EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours') were not found in the DataFrame, meaning the original dropping step was already redundant. No other constant or unique columns were identified. The 'Attrition' column still contains 'Yes'/'No' string values, indicating that the encoding step (Cell FdjUhe88i2E5) has not yet been applied. Therefore, the next step is to apply the encoding to the 'Attrition' column and then verify the change.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac684df1",
        "outputId": "45eceeba-ff95-41fe-ca63-38328eb8d8bb"
      },
      "source": [
        "df['Attrition'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "print(\"--- Verifying Target Variable Encoding ---\")\n",
        "print(\"Unique values in 'Attrition' column AFTER encoding:\")\n",
        "print(df['Attrition'].value_counts())\n",
        "print(\"Data type of 'Attrition' column AFTER encoding:\", df['Attrition'].dtype)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Verifying Target Variable Encoding ---\n",
            "Unique values in 'Attrition' column AFTER encoding:\n",
            "Attrition\n",
            "0    1233\n",
            "1     237\n",
            "Name: count, dtype: int64\n",
            "Data type of 'Attrition' column AFTER encoding: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41b2c112"
      },
      "source": [
        "## Review Feature Engineering\n",
        "\n",
        "### Subtask:\n",
        "Analyze the created features (Tenure_Ratio, Income_Band, Promotion_Gap) to confirm their validity and potential impact on the models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08b9de93"
      },
      "source": [
        "**Reasoning**:\n",
        "To analyze the newly created features, I will display the head of the DataFrame, check for missing values and descriptive statistics for 'Tenure_Ratio', examine the unique values and counts for 'Income_Band', calculate descriptive statistics for 'Promotion_Gap', and verify the data types of all three columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "1d29548c",
        "outputId": "90675ece-755c-43e7-ead4-292a998d28f8"
      },
      "source": [
        "print(\"--- Reviewing Newly Created Features ---\")\n",
        "print(\"DataFrame Head with new features:\")\n",
        "print(df[['Tenure_Ratio', 'Income_Band', 'Promotion_Gap']].head())\n",
        "\n",
        "print(\"\\n--- Analyzing Tenure_Ratio ---\")\n",
        "print(\"Missing values in 'Tenure_Ratio':\", df['Tenure_Ratio'].isnull().sum())\n",
        "print(\"Descriptive statistics for 'Tenure_Ratio':\\n\", df['Tenure_Ratio'].describe())\n",
        "# Explain origin of NaNs\n",
        "if (df['TotalWorkingYears'] == 0).any():\n",
        "    print(\"Note: NaN values in 'Tenure_Ratio' likely originate from 'TotalWorkingYears' being 0, causing division by zero.\")\n",
        "\n",
        "print(\"\\n--- Analyzing Income_Band ---\")\n",
        "print(\"Unique values and counts for 'Income_Band':\\n\", df['Income_Band'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\n--- Analyzing Promotion_Gap ---\")\n",
        "print(\"Descriptive statistics for 'Promotion_Gap':\\n\", df['Promotion_Gap'].describe())\n",
        "\n",
        "print(\"\\n--- Data Types of New Features ---\")\n",
        "print(df[['Tenure_Ratio', 'Income_Band', 'Promotion_Gap']].dtypes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Reviewing Newly Created Features ---\n",
            "DataFrame Head with new features:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['Tenure_Ratio', 'Income_Band', 'Promotion_Gap'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-211652499.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Reviewing Newly Created Features ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame Head with new features:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tenure_Ratio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Income_Band'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Promotion_Gap'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Analyzing Tenure_Ratio ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Tenure_Ratio', 'Income_Band', 'Promotion_Gap'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9359aeb1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because the feature engineering step (creating 'Tenure_Ratio', 'Income_Band', 'Promotion_Gap') had not been executed, leading to a KeyError. I will first execute the feature engineering code and then the analysis code to correctly review the newly created features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24bb67af",
        "outputId": "0ea90463-4f25-4633-9ff5-adbda109a062"
      },
      "source": [
        "df['Tenure_Ratio'] = df['YearsAtCompany'] / df['TotalWorkingYears'].replace(0,np.nan)\n",
        "df['Income_Band'] = pd.qcut(df['MonthlyIncome'], 5, labels=False)\n",
        "df['Promotion_Gap'] = df['YearsAtCompany'] - df['YearsSinceLastPromotion']\n",
        "\n",
        "print(\"--- Reviewing Newly Created Features ---\")\n",
        "print(\"DataFrame Head with new features:\")\n",
        "print(df[['Tenure_Ratio', 'Income_Band', 'Promotion_Gap']].head())\n",
        "\n",
        "print(\"\\n--- Analyzing Tenure_Ratio ---\")\n",
        "print(\"Missing values in 'Tenure_Ratio':\", df['Tenure_Ratio'].isnull().sum())\n",
        "print(\"Descriptive statistics for 'Tenure_Ratio':\\n\", df['Tenure_Ratio'].describe())\n",
        "# Explain origin of NaNs\n",
        "if (df['TotalWorkingYears'] == 0).any():\n",
        "    print(\"Note: NaN values in 'Tenure_Ratio' likely originate from 'TotalWorkingYears' being 0, causing division by zero.\")\n",
        "\n",
        "print(\"\\n--- Analyzing Income_Band ---\")\n",
        "print(\"Unique values and counts for 'Income_Band':\\n\", df['Income_Band'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\n--- Analyzing Promotion_Gap ---\")\n",
        "print(\"Descriptive statistics for 'Promotion_Gap':\\n\", df['Promotion_Gap'].describe())\n",
        "\n",
        "print(\"\\n--- Data Types of New Features ---\")\n",
        "print(df[['Tenure_Ratio', 'Income_Band', 'Promotion_Gap']].dtypes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Reviewing Newly Created Features ---\n",
            "DataFrame Head with new features:\n",
            "   Tenure_Ratio  Income_Band  Promotion_Gap\n",
            "0      0.750000            3              6\n",
            "1      1.000000            2              9\n",
            "2      0.000000            0              0\n",
            "3      1.000000            1              5\n",
            "4      0.333333            1              0\n",
            "\n",
            "--- Analyzing Tenure_Ratio ---\n",
            "Missing values in 'Tenure_Ratio': 11\n",
            "Descriptive statistics for 'Tenure_Ratio':\n",
            " count    1459.000000\n",
            "mean        0.683186\n",
            "std         0.323978\n",
            "min         0.000000\n",
            "25%         0.419872\n",
            "50%         0.800000\n",
            "75%         1.000000\n",
            "max         1.000000\n",
            "Name: Tenure_Ratio, dtype: float64\n",
            "Note: NaN values in 'Tenure_Ratio' likely originate from 'TotalWorkingYears' being 0, causing division by zero.\n",
            "\n",
            "--- Analyzing Income_Band ---\n",
            "Unique values and counts for 'Income_Band':\n",
            " Income_Band\n",
            "0    294\n",
            "1    294\n",
            "2    294\n",
            "3    294\n",
            "4    294\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Analyzing Promotion_Gap ---\n",
            "Descriptive statistics for 'Promotion_Gap':\n",
            " count    1470.000000\n",
            "mean        4.820408\n",
            "std         4.847756\n",
            "min         0.000000\n",
            "25%         1.000000\n",
            "50%         4.000000\n",
            "75%         7.000000\n",
            "max        36.000000\n",
            "Name: Promotion_Gap, dtype: float64\n",
            "\n",
            "--- Data Types of New Features ---\n",
            "Tenure_Ratio     float64\n",
            "Income_Band        int64\n",
            "Promotion_Gap      int64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "509d63e9"
      },
      "source": [
        "## Review Data Preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Verify the one-hot encoding, train-test split, and feature scaling steps, ensuring they are applied correctly and prevent data leakage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80716e18"
      },
      "source": [
        "## Review Data Preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Verify the one-hot encoding, train-test split, and feature scaling steps, ensuring they are applied correctly and prevent data leakage.\n",
        "\n",
        "#### Instructions\n",
        "1. Inspect the columns of the `X` DataFrame before and after one-hot encoding using `X.head()` and `X.info()` to confirm the transformation of categorical features and the creation of new dummy variables. Pay attention to the number of columns.\n",
        "2. Check the shapes of `X_train`, `X_test`, `y_train`, and `y_test` to confirm the train-test split proportions (e.g., `X_train.shape`, `X_test.shape`, `y_train.shape`, `y_test.shape`).\n",
        "3. Verify the stratification of the `y` variable by comparing the value counts of `y_train` and `y_test` (e.g., `y_train.value_counts(normalize=True)` and `y_test.value_counts(normalize=True)`).\n",
        "4. Examine the descriptive statistics (mean and standard deviation) of `X_train` and `X_test` after scaling to confirm that the `StandardScaler` has been applied correctly (e.g., `pd.DataFrame(X_train).describe()` and `pd.DataFrame(X_test).describe()`). Ensure that `X_train` has a mean close to 0 and a standard deviation close to 1 for each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b0f66c3"
      },
      "source": [
        "**Reasoning**:\n",
        "To verify the one-hot encoding, train-test split, and feature scaling steps as outlined in the instructions, I will first recreate the `X` DataFrame before one-hot encoding, then apply the encoding and inspect the changes. After that, I will check the shapes and stratification of the train-test split, and finally, verify the feature scaling by examining descriptive statistics of the scaled training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f1304e3",
        "outputId": "e9193f48-d7dd-4b3b-f6df-3e516071c417"
      },
      "source": [
        "print(\"--- Reviewing One-Hot Encoding ---\")\n",
        "# Recreate X before one-hot encoding for comparison\n",
        "X_before_encoding = df.drop(\"Attrition\", axis=1)\n",
        "print(\"X before one-hot encoding (first 5 rows):\")\n",
        "print(X_before_encoding.head())\n",
        "print(\"\\nShape of X before one-hot encoding:\", X_before_encoding.shape)\n",
        "print(\"Info of X before one-hot encoding:\\n\")\n",
        "X_before_encoding.info(verbose=True, show_counts=True)\n",
        "\n",
        "# Perform one-hot encoding on X (as done in original notebook STEP 7)\n",
        "X = pd.get_dummies(X_before_encoding, drop_first=True)\n",
        "print(\"\\nX after one-hot encoding (first 5 rows):\")\n",
        "print(X.head())\n",
        "print(\"\\nShape of X after one-hot encoding:\", X.shape)\n",
        "print(\"Info of X after one-hot encoding:\\n\")\n",
        "X.info(verbose=True, show_counts=True)\n",
        "\n",
        "\n",
        "print(\"\\n--- Reviewing Train-Test Split ---\")\n",
        "# Ensure y is the target variable (as done in original notebook STEP 6)\n",
        "y = df['Attrition']\n",
        "\n",
        "# Perform train-test split (as done in original notebook STEP 8)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42, stratify=y)\n",
        "\n",
        "print(\"Shapes of datasets after train-test split:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nStratification check for target variable (y_train):\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nStratification check for target variable (y_test):\")\n",
        "print(y_test.value_counts(normalize=True))\n",
        "\n",
        "\n",
        "print(\"\\n--- Reviewing Feature Scaling ---\")\n",
        "# Perform feature scaling (as done in original notebook STEP 9)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Descriptive statistics for X_train after scaling (first 5 features):\\n\")\n",
        "# Convert scaled arrays back to DataFrame for easier inspection of descriptive stats\n",
        "# Only show first 5 columns for brevity, as the table can be very wide\n",
        "print(pd.DataFrame(X_train_scaled).iloc[:, :5].describe())\n",
        "\n",
        "print(\"\\nDescriptive statistics for X_test after scaling (first 5 features):\\n\")\n",
        "print(pd.DataFrame(X_test_scaled).iloc[:, :5].describe())\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Reviewing One-Hot Encoding ---\n",
            "X before one-hot encoding (first 5 rows):\n",
            "   Age     BusinessTravel  DailyRate              Department  \\\n",
            "0   41      Travel_Rarely       1102                   Sales   \n",
            "1   49  Travel_Frequently        279  Research & Development   \n",
            "2   37      Travel_Rarely       1373  Research & Development   \n",
            "3   33  Travel_Frequently       1392  Research & Development   \n",
            "4   27      Travel_Rarely        591  Research & Development   \n",
            "\n",
            "   DistanceFromHome      Education EducationField EnvironmentSatisfaction  \\\n",
            "0                 1        College  Life Sciences                  Medium   \n",
            "1                 8  Below College  Life Sciences                    High   \n",
            "2                 2        College          Other               Very High   \n",
            "3                 3         Master  Life Sciences               Very High   \n",
            "4                 2  Below College        Medical                     Low   \n",
            "\n",
            "   Gender  HourlyRate  ... TotalWorkingYears TrainingTimesLastYear  \\\n",
            "0  Female          94  ...                 8                     0   \n",
            "1    Male          61  ...                10                     3   \n",
            "2    Male          92  ...                 7                     3   \n",
            "3  Female          56  ...                 8                     3   \n",
            "4    Male          40  ...                 6                     3   \n",
            "\n",
            "  WorkLifeBalance YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
            "0             Bad              6                  4                        0   \n",
            "1          Better             10                  7                        1   \n",
            "2          Better              0                  0                        0   \n",
            "3          Better              8                  7                        3   \n",
            "4          Better              2                  2                        2   \n",
            "\n",
            "   YearsWithCurrManager  Tenure_Ratio Income_Band  Promotion_Gap  \n",
            "0                     5      0.750000           3              6  \n",
            "1                     7      1.000000           2              9  \n",
            "2                     0      0.000000           0              0  \n",
            "3                     0      1.000000           1              5  \n",
            "4                     2      0.333333           1              0  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "\n",
            "Shape of X before one-hot encoding: (1470, 33)\n",
            "Info of X before one-hot encoding:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 33 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Age                       1470 non-null   int64  \n",
            " 1   BusinessTravel            1470 non-null   object \n",
            " 2   DailyRate                 1470 non-null   int64  \n",
            " 3   Department                1470 non-null   object \n",
            " 4   DistanceFromHome          1470 non-null   int64  \n",
            " 5   Education                 1470 non-null   object \n",
            " 6   EducationField            1470 non-null   object \n",
            " 7   EnvironmentSatisfaction   1470 non-null   object \n",
            " 8   Gender                    1470 non-null   object \n",
            " 9   HourlyRate                1470 non-null   int64  \n",
            " 10  JobInvolvement            1470 non-null   object \n",
            " 11  JobLevel                  1470 non-null   object \n",
            " 12  JobRole                   1470 non-null   object \n",
            " 13  JobSatisfaction           1470 non-null   object \n",
            " 14  MaritalStatus             1470 non-null   object \n",
            " 15  MonthlyIncome             1470 non-null   int64  \n",
            " 16  MonthlyRate               1470 non-null   int64  \n",
            " 17  NumCompaniesWorked        1470 non-null   int64  \n",
            " 18  OverTime                  1470 non-null   object \n",
            " 19  PercentSalaryHike         1470 non-null   int64  \n",
            " 20  PerformanceRating         1470 non-null   object \n",
            " 21  RelationshipSatisfaction  1470 non-null   object \n",
            " 22  StockOptionLevel          1470 non-null   int64  \n",
            " 23  TotalWorkingYears         1470 non-null   int64  \n",
            " 24  TrainingTimesLastYear     1470 non-null   int64  \n",
            " 25  WorkLifeBalance           1470 non-null   object \n",
            " 26  YearsAtCompany            1470 non-null   int64  \n",
            " 27  YearsInCurrentRole        1470 non-null   int64  \n",
            " 28  YearsSinceLastPromotion   1470 non-null   int64  \n",
            " 29  YearsWithCurrManager      1470 non-null   int64  \n",
            " 30  Tenure_Ratio              1459 non-null   float64\n",
            " 31  Income_Band               1470 non-null   int64  \n",
            " 32  Promotion_Gap             1470 non-null   int64  \n",
            "dtypes: float64(1), int64(17), object(15)\n",
            "memory usage: 379.1+ KB\n",
            "\n",
            "X after one-hot encoding (first 5 rows):\n",
            "   Age  DailyRate  DistanceFromHome  HourlyRate  MonthlyIncome  MonthlyRate  \\\n",
            "0   41       1102                 1          94           5993        19479   \n",
            "1   49        279                 8          61           5130        24907   \n",
            "2   37       1373                 2          92           2090         2396   \n",
            "3   33       1392                 3          56           2909        23159   \n",
            "4   27        591                 2          40           3468        16632   \n",
            "\n",
            "   NumCompaniesWorked  PercentSalaryHike  StockOptionLevel  TotalWorkingYears  \\\n",
            "0                   8                 11                 0                  8   \n",
            "1                   1                 23                 1                 10   \n",
            "2                   6                 15                 0                  7   \n",
            "3                   1                 11                 0                  8   \n",
            "4                   9                 12                 1                  6   \n",
            "\n",
            "   ...  MaritalStatus_Married  MaritalStatus_Single  OverTime_Yes  \\\n",
            "0  ...                  False                  True          True   \n",
            "1  ...                   True                 False         False   \n",
            "2  ...                  False                  True          True   \n",
            "3  ...                   True                 False          True   \n",
            "4  ...                   True                 False         False   \n",
            "\n",
            "   PerformanceRating_Outstanding  RelationshipSatisfaction_Low  \\\n",
            "0                          False                          True   \n",
            "1                           True                         False   \n",
            "2                          False                         False   \n",
            "3                          False                         False   \n",
            "4                          False                         False   \n",
            "\n",
            "   RelationshipSatisfaction_Medium  RelationshipSatisfaction_Very High  \\\n",
            "0                            False                               False   \n",
            "1                            False                                True   \n",
            "2                             True                               False   \n",
            "3                            False                               False   \n",
            "4                            False                                True   \n",
            "\n",
            "   WorkLifeBalance_Best  WorkLifeBalance_Better  WorkLifeBalance_Good  \n",
            "0                 False                   False                 False  \n",
            "1                 False                    True                 False  \n",
            "2                 False                    True                 False  \n",
            "3                 False                    True                 False  \n",
            "4                 False                    True                 False  \n",
            "\n",
            "[5 rows x 63 columns]\n",
            "\n",
            "Shape of X after one-hot encoding: (1470, 63)\n",
            "Info of X after one-hot encoding:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 63 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   Age                                 1470 non-null   int64  \n",
            " 1   DailyRate                           1470 non-null   int64  \n",
            " 2   DistanceFromHome                    1470 non-null   int64  \n",
            " 3   HourlyRate                          1470 non-null   int64  \n",
            " 4   MonthlyIncome                       1470 non-null   int64  \n",
            " 5   MonthlyRate                         1470 non-null   int64  \n",
            " 6   NumCompaniesWorked                  1470 non-null   int64  \n",
            " 7   PercentSalaryHike                   1470 non-null   int64  \n",
            " 8   StockOptionLevel                    1470 non-null   int64  \n",
            " 9   TotalWorkingYears                   1470 non-null   int64  \n",
            " 10  TrainingTimesLastYear               1470 non-null   int64  \n",
            " 11  YearsAtCompany                      1470 non-null   int64  \n",
            " 12  YearsInCurrentRole                  1470 non-null   int64  \n",
            " 13  YearsSinceLastPromotion             1470 non-null   int64  \n",
            " 14  YearsWithCurrManager                1470 non-null   int64  \n",
            " 15  Tenure_Ratio                        1459 non-null   float64\n",
            " 16  Income_Band                         1470 non-null   int64  \n",
            " 17  Promotion_Gap                       1470 non-null   int64  \n",
            " 18  BusinessTravel_Travel_Frequently    1470 non-null   bool   \n",
            " 19  BusinessTravel_Travel_Rarely        1470 non-null   bool   \n",
            " 20  Department_Research & Development   1470 non-null   bool   \n",
            " 21  Department_Sales                    1470 non-null   bool   \n",
            " 22  Education_Below College             1470 non-null   bool   \n",
            " 23  Education_College                   1470 non-null   bool   \n",
            " 24  Education_Doctor                    1470 non-null   bool   \n",
            " 25  Education_Master                    1470 non-null   bool   \n",
            " 26  EducationField_Life Sciences        1470 non-null   bool   \n",
            " 27  EducationField_Marketing            1470 non-null   bool   \n",
            " 28  EducationField_Medical              1470 non-null   bool   \n",
            " 29  EducationField_Other                1470 non-null   bool   \n",
            " 30  EducationField_Technical Degree     1470 non-null   bool   \n",
            " 31  EnvironmentSatisfaction_Low         1470 non-null   bool   \n",
            " 32  EnvironmentSatisfaction_Medium      1470 non-null   bool   \n",
            " 33  EnvironmentSatisfaction_Very High   1470 non-null   bool   \n",
            " 34  Gender_Male                         1470 non-null   bool   \n",
            " 35  JobInvolvement_Low                  1470 non-null   bool   \n",
            " 36  JobInvolvement_Medium               1470 non-null   bool   \n",
            " 37  JobInvolvement_Very High            1470 non-null   bool   \n",
            " 38  JobLevel_Executive Level            1470 non-null   bool   \n",
            " 39  JobLevel_Junior Level               1470 non-null   bool   \n",
            " 40  JobLevel_Mid Level                  1470 non-null   bool   \n",
            " 41  JobLevel_Senior Level               1470 non-null   bool   \n",
            " 42  JobRole_Human Resources             1470 non-null   bool   \n",
            " 43  JobRole_Laboratory Technician       1470 non-null   bool   \n",
            " 44  JobRole_Manager                     1470 non-null   bool   \n",
            " 45  JobRole_Manufacturing Director      1470 non-null   bool   \n",
            " 46  JobRole_Research Director           1470 non-null   bool   \n",
            " 47  JobRole_Research Scientist          1470 non-null   bool   \n",
            " 48  JobRole_Sales Executive             1470 non-null   bool   \n",
            " 49  JobRole_Sales Representative        1470 non-null   bool   \n",
            " 50  JobSatisfaction_Low                 1470 non-null   bool   \n",
            " 51  JobSatisfaction_Medium              1470 non-null   bool   \n",
            " 52  JobSatisfaction_Very High           1470 non-null   bool   \n",
            " 53  MaritalStatus_Married               1470 non-null   bool   \n",
            " 54  MaritalStatus_Single                1470 non-null   bool   \n",
            " 55  OverTime_Yes                        1470 non-null   bool   \n",
            " 56  PerformanceRating_Outstanding       1470 non-null   bool   \n",
            " 57  RelationshipSatisfaction_Low        1470 non-null   bool   \n",
            " 58  RelationshipSatisfaction_Medium     1470 non-null   bool   \n",
            " 59  RelationshipSatisfaction_Very High  1470 non-null   bool   \n",
            " 60  WorkLifeBalance_Best                1470 non-null   bool   \n",
            " 61  WorkLifeBalance_Better              1470 non-null   bool   \n",
            " 62  WorkLifeBalance_Good                1470 non-null   bool   \n",
            "dtypes: bool(45), float64(1), int64(17)\n",
            "memory usage: 271.4 KB\n",
            "\n",
            "--- Reviewing Train-Test Split ---\n",
            "Shapes of datasets after train-test split:\n",
            "X_train shape: (1176, 63)\n",
            "X_test shape: (294, 63)\n",
            "y_train shape: (1176,)\n",
            "y_test shape: (294,)\n",
            "\n",
            "Stratification check for target variable (y_train):\n",
            "Attrition\n",
            "0    0.838435\n",
            "1    0.161565\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Stratification check for target variable (y_test):\n",
            "Attrition\n",
            "0    0.840136\n",
            "1    0.159864\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "--- Reviewing Feature Scaling ---\n",
            "Descriptive statistics for X_train after scaling (first 5 features):\n",
            "\n",
            "                  0             1             2             3             4\n",
            "count  1.176000e+03  1.176000e+03  1.176000e+03  1.176000e+03  1.176000e+03\n",
            "mean  -4.229421e-17  1.359457e-16 -4.682573e-17 -3.776269e-18 -7.930164e-17\n",
            "std    1.000425e+00  1.000425e+00  1.000425e+00  1.000425e+00  1.000425e+00\n",
            "min   -2.070831e+00 -1.747373e+00 -1.022219e+00 -1.743216e+00 -1.189876e+00\n",
            "25%   -7.628207e-01 -8.381548e-01 -8.999145e-01 -8.593318e-01 -7.730452e-01\n",
            "50%   -1.088155e-01 -1.119603e-02 -2.883928e-01  2.455234e-02 -3.309550e-01\n",
            "75%    6.541906e-01  8.799502e-01  5.677376e-01  8.593318e-01  4.033900e-01\n",
            "max    2.507205e+00  1.732459e+00  2.402303e+00  1.694111e+00  2.886856e+00\n",
            "\n",
            "Descriptive statistics for X_test after scaling (first 5 features):\n",
            "\n",
            "                0           1           2           3           4\n",
            "count  294.000000  294.000000  294.000000  294.000000  294.000000\n",
            "mean    -0.040597   -0.018767   -0.101192    0.096038   -0.044170\n",
            "std      0.977899    1.028779    0.952343    0.987554    1.058439\n",
            "min     -2.070831   -1.749866   -1.022219   -1.743216   -1.180632\n",
            "25%     -0.762821   -0.899226   -0.899915   -0.748846   -0.793199\n",
            "50%     -0.217816    0.016224   -0.410697    0.073657   -0.432529\n",
            "75%      0.545190    0.936659    0.292553    0.957541    0.295904\n",
            "max      2.398204    1.722488    2.402303    1.694111    2.892445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3f5f020"
      },
      "source": [
        "## Review Model Training and Evaluation\n",
        "\n",
        "### Subtask:\n",
        "Assess the training of both Logistic Regression and Decision Tree models, and check the evaluation metrics and their interpretation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c466609a"
      },
      "source": [
        "### Subtask: Assess Model Training and Evaluation\n",
        "\n",
        "**Instructions Followed:**\n",
        "1. Verify that the `log_model` and `tree_model` objects exist and have been fitted to the training data.\n",
        "2. Review the classification reports and accuracy scores for both Logistic Regression and Decision Tree models.\n",
        "3. Interpret the precision, recall, f1-score, and support for both classes ('0' for No Attrition, '1' for Yes Attrition) for each model, with a focus on the minority class (Attrition: '1').\n",
        "4. Briefly summarize the strengths and weaknesses of each model based on these metrics.\n",
        "5. Generate and inspect the confusion matrices for both models to understand true positives, true negatives, false positives, and false negatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d2e1332"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin assessing the model training and evaluation as per the updated instructions, I will first verify the existence and fitted status of the `log_model` and `tree_model` objects, and then display the model objects to confirm their presence in the environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00d8870f",
        "outputId": "ada8a6e0-f444-4e03-9dab-2ff44847263b"
      },
      "source": [
        "print(\"--- Verifying Model Existence and Fitted Status ---\")\n",
        "\n",
        "if 'log_model' in locals() and log_model is not None:\n",
        "    print(\"Logistic Regression model (log_model) exists and is likely fitted.\")\n",
        "    print(log_model)\n",
        "else:\n",
        "    print(\"Logistic Regression model (log_model) not found or not fitted.\")\n",
        "\n",
        "if 'tree_model' in locals() and tree_model is not None:\n",
        "    print(\"\\nDecision Tree model (tree_model) exists and is likely fitted.\")\n",
        "    print(tree_model)\n",
        "else:\n",
        "    print(\"\\nDecision Tree model (tree_model) not found or not fitted.\")\n",
        "\n",
        "print(\"\\n--- Reviewing Classification Reports and Accuracy Scores (from previous output) ---\")\n",
        "# The classification reports and accuracy scores were already printed in the previous cell (Ez05OATcjcQ1).\n",
        "# We will now proceed to interpret them and then generate confusion matrices."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Verifying Model Existence and Fitted Status ---\n",
            "Logistic Regression model (log_model) not found or not fitted.\n",
            "\n",
            "Decision Tree model (tree_model) not found or not fitted.\n",
            "\n",
            "--- Reviewing Classification Reports and Accuracy Scores (from previous output) ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "083ac173"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous output indicated that the `log_model` and `tree_model` were not found or fitted. This implies that the model training step (Step 10) was not executed, or its state was lost. To proceed with model evaluation, I need to re-execute the model training and prediction steps (Steps 10 and 11) to ensure the models and their predictions are available in the kernel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "21cd8b53",
        "outputId": "ed0e1951-7c54-4c9b-82d4-c36c7aa0bf95"
      },
      "source": [
        "print(\"# STEP 10: TRAIN BOTH MODELS\")\n",
        "log_model = LogisticRegression(max_iter=2000)\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "tree_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"# STEP 11: MODEL PREDICTIONS\")\n",
        "log_pred = log_model.predict(X_test_scaled)\n",
        "tree_pred = tree_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Models trained and predictions made.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# STEP 10: TRAIN BOTH MODELS\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-463303582.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# STEP 10: TRAIN BOTH MODELS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlog_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtree_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m   1223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c6422e4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous error `ValueError: Input X contains NaN` indicates that the `StandardScaler` or the subsequent model training received data with missing values. The `Tenure_Ratio` column, created in Feature Engineering, introduces NaNs where `TotalWorkingYears` was zero. These NaNs must be handled before scaling and model training. I will impute the missing values in `Tenure_Ratio` with the mean of the training data after the train-test split and before scaling, to prevent data leakage and ensure clean data for the models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ebb73feb",
        "outputId": "93aa1e75-0ec5-43a3-9f6f-ee8ef9e79d89"
      },
      "source": [
        "print(\"--- Reviewing One-Hot Encoding ---\")\n",
        "# Recreate X before one-hot encoding for comparison\n",
        "X_before_encoding = df.drop(\"Attrition\", axis=1)\n",
        "print(\"X before one-hot encoding (first 5 rows):\")\n",
        "print(X_before_encoding.head())\n",
        "print(\"\\nShape of X before one-hot encoding:\", X_before_encoding.shape)\n",
        "print(\"Info of X before one-hot encoding:\\n\")\n",
        "X_before_encoding.info(verbose=True, show_counts=True)\n",
        "\n",
        "# Perform one-hot encoding on X (as done in original notebook STEP 7)\n",
        "X = pd.get_dummies(X_before_encoding, drop_first=True)\n",
        "print(\"\\nX after one-hot encoding (first 5 rows):\")\n",
        "print(X.head())\n",
        "print(\"\\nShape of X after one-hot encoding:\", X.shape)\n",
        "print(\"Info of X after one-hot encoding:\\n\")\n",
        "X.info(verbose=True, show_counts=True)\n",
        "\n",
        "\n",
        "print(\"\\n--- Reviewing Train-Test Split ---\")\n",
        "# Ensure y is the target variable (as done in original notebook STEP 6)\n",
        "y = df['Attrition']\n",
        "\n",
        "# Perform train-test split (as done in original notebook STEP 8)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42, stratify=y)\n",
        "\n",
        "print(\"Shapes of datasets after train-test split:\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "print(\"\\nStratification check for target variable (y_train):\")\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(\"\\nStratification check for target variable (y_test):\")\n",
        "print(y_test.value_counts(normalize=True))\n",
        "\n",
        "print(\"\\n--- Handling Missing Values (Imputation) ---\")\n",
        "# Identify columns with NaNs (Tenure_Ratio)\n",
        "nan_cols = X_train.columns[X_train.isnull().any()].tolist()\n",
        "if nan_cols:\n",
        "    print(f\"Columns with NaNs identified in X_train: {nan_cols}\")\n",
        "    for col in nan_cols:\n",
        "        # Impute NaNs using the mean of the training set to prevent data leakage\n",
        "        mean_val = X_train[col].mean()\n",
        "        X_train[col].fillna(mean_val, inplace=True)\n",
        "        X_test[col].fillna(mean_val, inplace=True)\n",
        "        print(f\"  NaNs in '{col}' imputed with mean from X_train ({mean_val:.4f}).\")\n",
        "else:\n",
        "    print(\"No NaNs found in X_train after split.\")\n",
        "\n",
        "print(\"\\nNaN check after imputation:\")\n",
        "print(f\"NaNs in X_train: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"NaNs in X_test: {X_test.isnull().sum().sum()}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Reviewing Feature Scaling ---\")\n",
        "# Perform feature scaling (as done in original notebook STEP 9)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Descriptive statistics for X_train after scaling (first 5 features):\\n\")\n",
        "# Convert scaled arrays back to DataFrame for easier inspection of descriptive stats\n",
        "# Only show first 5 columns for brevity, as the table can be very wide\n",
        "print(pd.DataFrame(X_train_scaled).iloc[:, :5].describe())\n",
        "\n",
        "print(\"\\nDescriptive statistics for X_test after scaling (first 5 features):\\n\")\n",
        "print(pd.DataFrame(X_test_scaled).iloc[:, :5].describe())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Reviewing One-Hot Encoding ---\n",
            "X before one-hot encoding (first 5 rows):\n",
            "   Age     BusinessTravel  DailyRate              Department  \\\n",
            "0   41      Travel_Rarely       1102                   Sales   \n",
            "1   49  Travel_Frequently        279  Research & Development   \n",
            "2   37      Travel_Rarely       1373  Research & Development   \n",
            "3   33  Travel_Frequently       1392  Research & Development   \n",
            "4   27      Travel_Rarely        591  Research & Development   \n",
            "\n",
            "   DistanceFromHome      Education EducationField EnvironmentSatisfaction  \\\n",
            "0                 1        College  Life Sciences                  Medium   \n",
            "1                 8  Below College  Life Sciences                    High   \n",
            "2                 2        College          Other               Very High   \n",
            "3                 3         Master  Life Sciences               Very High   \n",
            "4                 2  Below College        Medical                     Low   \n",
            "\n",
            "   Gender  HourlyRate  ... TotalWorkingYears TrainingTimesLastYear  \\\n",
            "0  Female          94  ...                 8                     0   \n",
            "1    Male          61  ...                10                     3   \n",
            "2    Male          92  ...                 7                     3   \n",
            "3  Female          56  ...                 8                     3   \n",
            "4    Male          40  ...                 6                     3   \n",
            "\n",
            "  WorkLifeBalance YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
            "0             Bad              6                  4                        0   \n",
            "1          Better             10                  7                        1   \n",
            "2          Better              0                  0                        0   \n",
            "3          Better              8                  7                        3   \n",
            "4          Better              2                  2                        2   \n",
            "\n",
            "   YearsWithCurrManager  Tenure_Ratio Income_Band  Promotion_Gap  \n",
            "0                     5      0.750000           3              6  \n",
            "1                     7      1.000000           2              9  \n",
            "2                     0      0.000000           0              0  \n",
            "3                     0      1.000000           1              5  \n",
            "4                     2      0.333333           1              0  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "\n",
            "Shape of X before one-hot encoding: (1470, 33)\n",
            "Info of X before one-hot encoding:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 33 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Age                       1470 non-null   int64  \n",
            " 1   BusinessTravel            1470 non-null   object \n",
            " 2   DailyRate                 1470 non-null   int64  \n",
            " 3   Department                1470 non-null   object \n",
            " 4   DistanceFromHome          1470 non-null   int64  \n",
            " 5   Education                 1470 non-null   object \n",
            " 6   EducationField            1470 non-null   object \n",
            " 7   EnvironmentSatisfaction   1470 non-null   object \n",
            " 8   Gender                    1470 non-null   object \n",
            " 9   HourlyRate                1470 non-null   int64  \n",
            " 10  JobInvolvement            1470 non-null   object \n",
            " 11  JobLevel                  1470 non-null   object \n",
            " 12  JobRole                   1470 non-null   object \n",
            " 13  JobSatisfaction           1470 non-null   object \n",
            " 14  MaritalStatus             1470 non-null   object \n",
            " 15  MonthlyIncome             1470 non-null   int64  \n",
            " 16  MonthlyRate               1470 non-null   int64  \n",
            " 17  NumCompaniesWorked        1470 non-null   int64  \n",
            " 18  OverTime                  1470 non-null   object \n",
            " 19  PercentSalaryHike         1470 non-null   int64  \n",
            " 20  PerformanceRating         1470 non-null   object \n",
            " 21  RelationshipSatisfaction  1470 non-null   object \n",
            " 22  StockOptionLevel          1470 non-null   int64  \n",
            " 23  TotalWorkingYears         1470 non-null   int64  \n",
            " 24  TrainingTimesLastYear     1470 non-null   int64  \n",
            " 25  WorkLifeBalance           1470 non-null   object \n",
            " 26  YearsAtCompany            1470 non-null   int64  \n",
            " 27  YearsInCurrentRole        1470 non-null   int64  \n",
            " 28  YearsSinceLastPromotion   1470 non-null   int64  \n",
            " 29  YearsWithCurrManager      1470 non-null   int64  \n",
            " 30  Tenure_Ratio              1459 non-null   float64\n",
            " 31  Income_Band               1470 non-null   int64  \n",
            " 32  Promotion_Gap             1470 non-null   int64  \n",
            "dtypes: float64(1), int64(17), object(15)\n",
            "memory usage: 379.1+ KB\n",
            "\n",
            "X after one-hot encoding (first 5 rows):\n",
            "   Age  DailyRate  DistanceFromHome  HourlyRate  MonthlyIncome  MonthlyRate  \\\n",
            "0   41       1102                 1          94           5993        19479   \n",
            "1   49        279                 8          61           5130        24907   \n",
            "2   37       1373                 2          92           2090         2396   \n",
            "3   33       1392                 3          56           2909        23159   \n",
            "4   27        591                 2          40           3468        16632   \n",
            "\n",
            "   NumCompaniesWorked  PercentSalaryHike  StockOptionLevel  TotalWorkingYears  \\\n",
            "0                   8                 11                 0                  8   \n",
            "1                   1                 23                 1                 10   \n",
            "2                   6                 15                 0                  7   \n",
            "3                   1                 11                 0                  8   \n",
            "4                   9                 12                 1                  6   \n",
            "\n",
            "   ...  MaritalStatus_Married  MaritalStatus_Single  OverTime_Yes  \\\n",
            "0  ...                  False                  True          True   \n",
            "1  ...                   True                 False         False   \n",
            "2  ...                  False                  True          True   \n",
            "3  ...                   True                 False          True   \n",
            "4  ...                   True                 False         False   \n",
            "\n",
            "   PerformanceRating_Outstanding  RelationshipSatisfaction_Low  \\\n",
            "0                          False                          True   \n",
            "1                           True                         False   \n",
            "2                          False                         False   \n",
            "3                          False                         False   \n",
            "4                          False                         False   \n",
            "\n",
            "   RelationshipSatisfaction_Medium  RelationshipSatisfaction_Very High  \\\n",
            "0                            False                               False   \n",
            "1                            False                                True   \n",
            "2                             True                               False   \n",
            "3                            False                               False   \n",
            "4                            False                                True   \n",
            "\n",
            "   WorkLifeBalance_Best  WorkLifeBalance_Better  WorkLifeBalance_Good  \n",
            "0                 False                   False                 False  \n",
            "1                 False                    True                 False  \n",
            "2                 False                    True                 False  \n",
            "3                 False                    True                 False  \n",
            "4                 False                    True                 False  \n",
            "\n",
            "[5 rows x 63 columns]\n",
            "\n",
            "Shape of X after one-hot encoding: (1470, 63)\n",
            "Info of X after one-hot encoding:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 63 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   Age                                 1470 non-null   int64  \n",
            " 1   DailyRate                           1470 non-null   int64  \n",
            " 2   DistanceFromHome                    1470 non-null   int64  \n",
            " 3   HourlyRate                          1470 non-null   int64  \n",
            " 4   MonthlyIncome                       1470 non-null   int64  \n",
            " 5   MonthlyRate                         1470 non-null   int64  \n",
            " 6   NumCompaniesWorked                  1470 non-null   int64  \n",
            " 7   PercentSalaryHike                   1470 non-null   int64  \n",
            " 8   StockOptionLevel                    1470 non-null   int64  \n",
            " 9   TotalWorkingYears                   1470 non-null   int64  \n",
            " 10  TrainingTimesLastYear               1470 non-null   int64  \n",
            " 11  YearsAtCompany                      1470 non-null   int64  \n",
            " 12  YearsInCurrentRole                  1470 non-null   int64  \n",
            " 13  YearsSinceLastPromotion             1470 non-null   int64  \n",
            " 14  YearsWithCurrManager                1470 non-null   int64  \n",
            " 15  Tenure_Ratio                        1459 non-null   float64\n",
            " 16  Income_Band                         1470 non-null   int64  \n",
            " 17  Promotion_Gap                       1470 non-null   int64  \n",
            " 18  BusinessTravel_Travel_Frequently    1470 non-null   bool   \n",
            " 19  BusinessTravel_Travel_Rarely        1470 non-null   bool   \n",
            " 20  Department_Research & Development   1470 non-null   bool   \n",
            " 21  Department_Sales                    1470 non-null   bool   \n",
            " 22  Education_Below College             1470 non-null   bool   \n",
            " 23  Education_College                   1470 non-null   bool   \n",
            " 24  Education_Doctor                    1470 non-null   bool   \n",
            " 25  Education_Master                    1470 non-null   bool   \n",
            " 26  EducationField_Life Sciences        1470 non-null   bool   \n",
            " 27  EducationField_Marketing            1470 non-null   bool   \n",
            " 28  EducationField_Medical              1470 non-null   bool   \n",
            " 29  EducationField_Other                1470 non-null   bool   \n",
            " 30  EducationField_Technical Degree     1470 non-null   bool   \n",
            " 31  EnvironmentSatisfaction_Low         1470 non-null   bool   \n",
            " 32  EnvironmentSatisfaction_Medium      1470 non-null   bool   \n",
            " 33  EnvironmentSatisfaction_Very High   1470 non-null   bool   \n",
            " 34  Gender_Male                         1470 non-null   bool   \n",
            " 35  JobInvolvement_Low                  1470 non-null   bool   \n",
            " 36  JobInvolvement_Medium               1470 non-null   bool   \n",
            " 37  JobInvolvement_Very High            1470 non-null   bool   \n",
            " 38  JobLevel_Executive Level            1470 non-null   bool   \n",
            " 39  JobLevel_Junior Level               1470 non-null   bool   \n",
            " 40  JobLevel_Mid Level                  1470 non-null   bool   \n",
            " 41  JobLevel_Senior Level               1470 non-null   bool   \n",
            " 42  JobRole_Human Resources             1470 non-null   bool   \n",
            " 43  JobRole_Laboratory Technician       1470 non-null   bool   \n",
            " 44  JobRole_Manager                     1470 non-null   bool   \n",
            " 45  JobRole_Manufacturing Director      1470 non-null   bool   \n",
            " 46  JobRole_Research Director           1470 non-null   bool   \n",
            " 47  JobRole_Research Scientist          1470 non-null   bool   \n",
            " 48  JobRole_Sales Executive             1470 non-null   bool   \n",
            " 49  JobRole_Sales Representative        1470 non-null   bool   \n",
            " 50  JobSatisfaction_Low                 1470 non-null   bool   \n",
            " 51  JobSatisfaction_Medium              1470 non-null   bool   \n",
            " 52  JobSatisfaction_Very High           1470 non-null   bool   \n",
            " 53  MaritalStatus_Married               1470 non-null   bool   \n",
            " 54  MaritalStatus_Single                1470 non-null   bool   \n",
            " 55  OverTime_Yes                        1470 non-null   bool   \n",
            " 56  PerformanceRating_Outstanding       1470 non-null   bool   \n",
            " 57  RelationshipSatisfaction_Low        1470 non-null   bool   \n",
            " 58  RelationshipSatisfaction_Medium     1470 non-null   bool   \n",
            " 59  RelationshipSatisfaction_Very High  1470 non-null   bool   \n",
            " 60  WorkLifeBalance_Best                1470 non-null   bool   \n",
            " 61  WorkLifeBalance_Better              1470 non-null   bool   \n",
            " 62  WorkLifeBalance_Good                1470 non-null   bool   \n",
            "dtypes: bool(45), float64(1), int64(17)\n",
            "memory usage: 271.4 KB\n",
            "\n",
            "--- Reviewing Train-Test Split ---\n",
            "Shapes of datasets after train-test split:\n",
            "X_train shape: (1176, 63)\n",
            "X_test shape: (294, 63)\n",
            "y_train shape: (1176,)\n",
            "y_test shape: (294,)\n",
            "\n",
            "Stratification check for target variable (y_train):\n",
            "Attrition\n",
            "0    0.838435\n",
            "1    0.161565\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Stratification check for target variable (y_test):\n",
            "Attrition\n",
            "0    0.840136\n",
            "1    0.159864\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "--- Handling Missing Values (Imputation) ---\n",
            "Columns with NaNs identified in X_train: ['Tenure_Ratio']\n",
            "  NaNs in 'Tenure_Ratio' imputed with mean from X_train (0.6856).\n",
            "\n",
            "NaN check after imputation:\n",
            "NaNs in X_train: 0\n",
            "NaNs in X_test: 0\n",
            "\n",
            "--- Reviewing Feature Scaling ---\n",
            "Descriptive statistics for X_train after scaling (first 5 features):\n",
            "\n",
            "                  0             1             2             3             4\n",
            "count  1.176000e+03  1.176000e+03  1.176000e+03  1.176000e+03  1.176000e+03\n",
            "mean  -4.229421e-17  1.359457e-16 -4.682573e-17 -3.776269e-18 -7.930164e-17\n",
            "std    1.000425e+00  1.000425e+00  1.000425e+00  1.000425e+00  1.000425e+00\n",
            "min   -2.070831e+00 -1.747373e+00 -1.022219e+00 -1.743216e+00 -1.189876e+00\n",
            "25%   -7.628207e-01 -8.381548e-01 -8.999145e-01 -8.593318e-01 -7.730452e-01\n",
            "50%   -1.088155e-01 -1.119603e-02 -2.883928e-01  2.455234e-02 -3.309550e-01\n",
            "75%    6.541906e-01  8.799502e-01  5.677376e-01  8.593318e-01  4.033900e-01\n",
            "max    2.507205e+00  1.732459e+00  2.402303e+00  1.694111e+00  2.886856e+00\n",
            "\n",
            "Descriptive statistics for X_test after scaling (first 5 features):\n",
            "\n",
            "                0           1           2           3           4\n",
            "count  294.000000  294.000000  294.000000  294.000000  294.000000\n",
            "mean    -0.040597   -0.018767   -0.101192    0.096038   -0.044170\n",
            "std      0.977899    1.028779    0.952343    0.987554    1.058439\n",
            "min     -2.070831   -1.749866   -1.022219   -1.743216   -1.180632\n",
            "25%     -0.762821   -0.899226   -0.899915   -0.748846   -0.793199\n",
            "50%     -0.217816    0.016224   -0.410697    0.073657   -0.432529\n",
            "75%      0.545190    0.936659    0.292553    0.957541    0.295904\n",
            "max      2.398204    1.722488    2.402303    1.694111    2.892445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3518568059.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_train[col].fillna(mean_val, inplace=True)\n",
            "/tmp/ipython-input-3518568059.py:47: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  X_test[col].fillna(mean_val, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c67dcdc"
      },
      "source": [
        "**Reasoning**:\n",
        "The models were not found or fitted in the previous execution due to NaN values, which have now been handled. I will re-execute the model training and prediction steps using the `X_train_scaled` and `X_test_scaled` data, which are now free of NaNs. After training, I will then print the classification reports and generate confusion matrices for both models as requested in the subtask instructions, importing `confusion_matrix` if needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e97dd81"
      },
      "source": [
        "## Assess Model Training and Evaluation_Retry_2\n",
        "\n",
        "### Subtask:\n",
        "Re-train Logistic Regression and Decision Tree models, make predictions, and evaluate their performance using classification reports and confusion matrices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8398942c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully handled missing values and scaled the data. Now, as per the instructions, I will re-train both Logistic Regression and Decision Tree models using the cleaned and scaled training data, make predictions on the test set, and then evaluate their performance using classification reports, accuracy scores, and confusion matrices. This completes the model training and evaluation part of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6689bed1",
        "outputId": "6880565e-c06f-4195-ead9-c1cbb6d3ad92"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"# STEP 10: RE-TRAIN BOTH MODELS\")\n",
        "log_model = LogisticRegression(max_iter=2000, random_state=42) # Added random_state for reproducibility\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "tree_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"# STEP 11: MODEL PREDICTIONS\")\n",
        "log_pred = log_model.predict(X_test_scaled)\n",
        "tree_pred = tree_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"# STEP 12: MODEL EVALUATION\")\n",
        "\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "print(classification_report(y_test, log_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, log_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, log_pred))\n",
        "\n",
        "print(\"\\nDecision Tree Results:\")\n",
        "print(classification_report(y_test, tree_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, tree_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, tree_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# STEP 10: RE-TRAIN BOTH MODELS\n",
            "# STEP 11: MODEL PREDICTIONS\n",
            "# STEP 12: MODEL EVALUATION\n",
            "\n",
            "Logistic Regression Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.91       247\n",
            "           1       0.56      0.30      0.39        47\n",
            "\n",
            "    accuracy                           0.85       294\n",
            "   macro avg       0.72      0.63      0.65       294\n",
            "weighted avg       0.83      0.85      0.83       294\n",
            "\n",
            "Accuracy: 0.8503401360544217\n",
            "Confusion Matrix:\n",
            " [[236  11]\n",
            " [ 33  14]]\n",
            "\n",
            "Decision Tree Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91       247\n",
            "           1       0.45      0.19      0.27        47\n",
            "\n",
            "    accuracy                           0.83       294\n",
            "   macro avg       0.66      0.57      0.59       294\n",
            "weighted avg       0.80      0.83      0.80       294\n",
            "\n",
            "Accuracy: 0.8333333333333334\n",
            "Confusion Matrix:\n",
            " [[236  11]\n",
            " [ 38   9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d8db94e"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Add the provided summary about the preprocessing steps, feature engineering, model training and evaluation, and Power BI visualization to the notebook as a final overview.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1d6956c"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Both Logistic Regression and Decision Tree models were successfully re-trained and evaluated on the scaled data.\n",
        "*   **Logistic Regression Model** achieved an accuracy of approximately 85.03%. It performed well in identifying employees who would not attrit (Class 0), with 236 true negatives and 11 false positives. However, its performance was weaker for identifying employees who would attrit (Class 1), with 14 true positives and 33 false negatives.\n",
        "*   **Decision Tree Model** achieved a slightly lower accuracy of approximately 83.33%. Similar to Logistic Regression, it was better at predicting non-attrition (236 true negatives, 11 false positives) but struggled more with attrition cases (9 true positives, 38 false negatives).\n",
        "*   Both models showed a common challenge in predicting the minority class (attrition), indicated by lower recall and precision for Class 1 compared to Class 0.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Address Class Imbalance:** Given the weaker performance in predicting employee attrition (Class 1) for both models, explore techniques to handle class imbalance, such as oversampling the minority class, undersampling the majority class, or using algorithms robust to imbalance (e.g., SMOTE, Balanced Random Forest).\n",
        "*   **Model Optimization:** Further optimize the models by tuning hyperparameters using techniques like GridSearchCV or RandomizedSearchCV to potentially improve the recall and F1-score for the attrition class, which is often crucial in employee retention scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = X_test.copy()\n",
        "output['Actual_Attrition'] = y_test.values\n",
        "output['Predicted_Attrition'] = log_pred\n",
        "output['Prediction_Probability'] = log_model.predict_proba(X_test_scaled)[:,1] # Corrected to use X_test_scaled\n",
        "\n",
        "# Categorize risk based on probability\n",
        "output['Risk_Level'] = pd.cut(\n",
        "    output['Prediction_Probability'],\n",
        "    bins=[0,0.40,0.65,1],\n",
        "    labels=['Low','Medium','High']\n",
        ")\n",
        "\n",
        "output.to_csv(\"HR_Attrition_Model_Export.csv\", index=False)\n",
        "print(\"File Exported Successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX76kTvKp9sW",
        "outputId": "2d7bff6a-5423-4008-92a6-b2efc6517407"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Exported Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theme_json = {\n",
        "  \"name\": \"Lavender Analytics Theme\",\n",
        "  \"dataColors\": [\"#C9B7E9\", \"#7E60BC\", \"#53389E\", \"#AA98DA\", \"#E5DAF9\"],\n",
        "  \"background\": \"#FFFFFF\",\n",
        "  \"foreground\": \"#2C2C2C\",\n",
        "  \"tableAccent\": \"#7E60BC\",\n",
        "  \"visualStyles\": {\n",
        "    \"*\": {\n",
        "      \"*\": {\n",
        "        \"title\": [\n",
        "          {\n",
        "            \"fontSize\": 14,\n",
        "            \"fontFamily\": \"Segoe UI Semibold\",\n",
        "            \"color\": \"#53389E\"\n",
        "          }\n",
        "        ],\n",
        "        \"labels\": [\n",
        "          {\n",
        "            \"color\": \"#2C2C2C\"\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "display(theme_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "oIPqAoDYqGDT",
        "outputId": "08ad727b-dddc-4ce8-8fd1-5e6aef819707"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'name': 'Lavender Analytics Theme',\n",
              " 'dataColors': ['#C9B7E9', '#7E60BC', '#53389E', '#AA98DA', '#E5DAF9'],\n",
              " 'background': '#FFFFFF',\n",
              " 'foreground': '#2C2C2C',\n",
              " 'tableAccent': '#7E60BC',\n",
              " 'visualStyles': {'*': {'*': {'title': [{'fontSize': 14,\n",
              "      'fontFamily': 'Segoe UI Semibold',\n",
              "      'color': '#53389E'}],\n",
              "    'labels': [{'color': '#2C2C2C'}]}}}}"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}